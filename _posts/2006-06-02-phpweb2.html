---
layout: post
permalink: /2006/06/02/phpweb2.html
title: "PHPで書かれたwebサービスを高速化する2"
date: 2006-06-02T23:05:06.00+09:00
tags:
  - "masato"
categories:
  - "Tips"
---
前回のエントリ<a href="http://unoh.github.com/2006/05/23/phpweb.html">PHPで書かれたwebサービスを高速化する</a>では高速化のレベルのうち、最初の2段階「ハードウェアによる高速化」「ソフトウェアによる高速化」について書きました。<br />
今回は第2弾として「プログラムの工夫による高速化」について書きたいと思います。<br />
<br />
- DBへのアクセスは自分で抽象化する<br />
<br />
DBへのアクセスを高速化するためには、チューニングを行ったり複数台構成にするわけですが、<br />
広く使われているPear::DBとかadodbは複数台構成のDBに接続することを考慮されていません。<br />
Pear::DBやadodbはバックエンドに使って、ラッパークラスを作るようにしましょう。<br />
<br />
- 更新系クエリと読み出し系クエリのユーザを分ける<br />
<br />
これは高速化とは関係ないんですが、ぜひ実行してもらいたいので書きました。<br />
複数台構成のサーバにアクセスするときは更新系クエリはマスターに発行して、<br />
読み出し系クエリはスレーブに発行するので別々のコネクションを使います。<br />
<br />
この時にマスターに接続するユーザとスレーブに繋げるユーザを別にして、<br />
マスターへのユーザは更新権限があって、スレーブへのユーザは更新権限が*ない*ようにしましょう。<br />
<br />
ちょっとした工夫ですが、これだけでセキュリティレベルがぐんと上がります。<br />
<br />
- クエリキャッシュ<br />
<br />
ここでいうクエリキャッシュはDBレベルではなくアプリケーションレベルでのキャッシュです。<br />
DBのクエリキャッシュはテーブルが更新されるとキャッシュがクリアされてしまい、<br />
頻繁に更新されるテーブルに対しては有効に機能しません。<br />
<br />
世の中のデータには即時性の必要ないデータがいっぱいあって、<br />
即時性の必要ない遅延が許されるデータに対しては、<br />
DBからクエリした結果をそのままキャッシュします。<br />
<br />
次回以降はDBに直接アクセスせずにキャッシュしてデータを使用します。<br />
これやるだけでDBへの負荷が全然違います。<br />
<br />
僕が開発している<a href="http://photozou.jp/">フォト蔵</a>ではmemcachedを使ってクエリキャッシュしてます。<br />
memcachedはメモリ上にデータを置くので高速にアクセスすることができます。<br />
<br />
- プロファイルツールを使用する<br />
<br />
プログラムの処理の8割は2割のコードで動いているとよく言われますが、<br />
処理のボトルネックになっているところは大体決まってます。<br />
<br />
どこが処理が遅いのかを調べるのにプログラムを眺めるのは効率が悪いので、<br />
こういう場合はプロファイルしましょう。<br />
<br />
xdebugというPHPの拡張を使うとプロファイル情報を吐き出してくれます。<br />
それを WinCacheGrind のようなツールを使うとどの処理に時間がかかってるのか簡単に調べることができます。<br />
<br />
<br />
<br />
だいぶ長くなってきたので今日はこの辺で。<br />
他にもいろいろ工夫している部分はありますが、また今度気が向いたときにでも書きます。
